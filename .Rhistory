(nopat<-as.table(rbind (c(10,10,10,10,10,10), table(sample(1:6,60,replace=T)))));chisq.test(nopat)
(nopat<-as.table(rbind (c(10,10,10,10,10,10), table(sample(1:6,60,replace=T)))));chisq.test(nopat)
(nopat<-as.table(rbind (c(10,10,10,10,10,10), table(sample(1:6,60,replace=T)))));chisq.test(nopat)
(nopat<-as.table(rbind (c(10,10,10,10,10,10), table(sample(1:6,60,replace=T)))));fisher.test(nopat)
(nopat<-as.table(rbind (c(10,10,10,10,10,10), table(sample(1:6,60,replace=T)))));fisher.test(nopat)
(nopat<-as.table(rbind (c(10,10,10,10,10,10), table(sample(1:6,60,replace=T)))));fisher.test(nopat)
(nopat<-as.table(rbind (c(10,10,10,10,10,10), table(sample(1:6,60,replace=T)))));fisher.test(nopat)
(nopat<-as.table(rbind (c(10,10,10,10,10,10), table(sample(1:6,60,replace=T)))));fisher.test(nopat)
?pnorm
pnorm(4.4,4.1,.7,lower.tail=F)
4b<-rnorm(16,4.4,0.7);mean(4b);sd(4b)
tehtävä4<-rnorm(16,4.4,0.7);mean(4b);sd(4b)
tehtävä4<-rnorm(16,4.4,0.7);mean(tehtävä4);sd(tehtävä4)
tehtävä4<-rnorm(16,4.4,0.7);mean(tehtävä4);sd(tehtävä4)
tehtävä4<-rnorm(16,4.4,0.7);mean(tehtävä4);sd(tehtävä4)
tehtävä4<-rnorm(16,4.4,0.7);mean(tehtävä4);sd(tehtävä4)
tehtävä4<-rnorm(16,4.4,0.7);mean(tehtävä4);sd(tehtävä4)
tehtävä4<-rnorm(16,4.4,0.7);mean(tehtävä4);sd(tehtävä4)
tehtävä4<-rnorm(16,4.4,0.7);mean(tehtävä4);sd(tehtävä4)
tehtävä4<-rnorm(16,4.4,0.7);mean(tehtävä4);sd(tehtävä4)
tehtävä4a<-tehtävä4
zplot
4.4-4.1/.7/sqrt(16)
t.test
?t.test
rm(tehtävä4a)
rm(tehtävä4b)
rm(tehtävä4)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaEOECD<-rnorm(33,18.7578,6.874001);mean(lomaEOECD);sd(lomaEOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
lomaOECD<-rnorm(40,21.1,5.040795);mean(lomaOECD);sd(lomaOECD)
t.text(lomaEOECD,lomaOECD)
t.test(lomaEOECD,lomaOECD)
t.test(lomaEOECD,lomaOECD,l)
t.test(lomaEOECD,lomaOECD,alternative=l)
t.test(lomaEOECD,lomaOECD,alternative="less")
summary(lomaEOECD)
summary(lomaOECD)
?qbinom
qbinom(.95,1000,.56)
qbinom(.95,1000,.53)
qbinom(559,1000,.53,lower.tail=F)
pbinom(559,1000,.53,lower.tail=F)
qbinom(.95,1000,.53,lower.tail=F)
qbinom(.95,1000,.53,lower.tail=T)
qbinom(.05,1000,.53,lower.tail=F)
rm(uusib)
rm(tehtävä4)
rm(otos)
rm(numbat)
mean(MALUOtos)
mean(malu_otos)
4.3-1.96/2*.35/sqrt(10))
4.3-1.96/2*.35/sqrt(10)
4.3+1.96/2*.35/sqrt(10))
4.3+1.96/2*.35/sqrt(10)
qnorm(.95)
?qnorm
qnorm(.95)
load("~/.RData")
rm(wlp_spok_2012)
save.image("~/.RData")
library("gsubfn", lib.loc="C:/Program Files/R/R-3.2.4revised/library")
load("C:/Users/juho/Desktop/uus.RData")
length(unlist(strapply(bhmc17,"\\t",perl=T)))
Sys.setlocale()
Sys.setlocale()
Sys.setlocale()
Sys.setlocale()
?cor.test
as.table(rbind(c(148,80),c(101,74)))
chisq.test(as.table(rbind(c(148,80),c(101,74))))
load("C:/Users/juho/Desktop/uudetputsit.RData")
?pbinom
pbinom(1,10,1/3,lower.tail=T)
pbinom(0,10,1/3,lower.tail=T)
pbinom(2,10,1/3,lower.tail=T)
pbinom(3,10,1/3,lower.tail=T)
dbinom(0,10,1/3,lower.tail=T)
dbinom(0,10,1/3)
dbinom(1,10,1/3)
dbinom(2,10,1/3)
dbinom(3,10,1/3)
dbinom(4,10,1/3)
dbinom(9,10,1/3)
pbinom(0,size=10,prob=1/3,lower.tail=F)
qnorm(1.96,180,6)
?qnorm
pnorm(190,180,6)
pnorm(190,180,6)-pnorm(170,180,6)
qnorm(1.96)
pnorm(1.96)
pnorm(-1.96)
pnorm(1.71)
pbinom
?dbinom
dbinom(9,10,1/3)
?pbinom
pnorm(.95)
qnorm(.95)
Sys.getlocale()
Sys.setlocale("LC_MESSAGES", "en_US.UTF-8")
load("C:/Users/juho/Desktop/NOW_filtering.RData")
`16.01.gb` <- read.delim("C:/Users/juho/Desktop/16-01-gb.txt", header=FALSE, quote="", stringsAsFactors=FALSE)
View(`16.01.gb`)
str(16.01.gb)
wlp_nov16 <- read.delim("H:/16-01-gb.txt", header=FALSE, quote="", stringsAsFactors=FALSE)
View(wlp_nov16)
str(wlp_nov16$V1)
summary(wlp_nov16$V1)
zone-in<-wlp_nov16[wlp_nov16$V1 > 7174984 & wlp_nov16$V1 < 7174988,]
zone_in<-wlp_nov16[wlp_nov16$V1 > 7174984 & wlp_nov16$V1 < 7174988,]
View(zone_in)
load("C:/Users/juho/Desktop/NOW_filtering.RData")
View(lucky12)
View(now_sources_pt2)
load("C:/Users/juho/Desktop/NOW_sorting_upto26dec16.RData")
sources.16.12 <- read.delim("H:/sources-16-12.txt", header=FALSE, quote="", stringsAsFactors=FALSE, skipNul = T)
View(sources.16.12)
gb.all_dupesremaining<-rbind(now_sources_pt1[now_sources_pt1$V4=="GB",],now_sources_pt2[now_sources_pt2$V4=="GB",],sources.16.11[sources.16.11$V4=="GB",],sources.16.12[sources16.12$V4=="GB",])
gb.all_dupesremaining<-rbind(now_sources_pt1[now_sources_pt1$V4=="GB",],now_sources_pt2[now_sources_pt2$V4=="GB",],sources.16.11[sources.16.11$V4=="GB",],sources.16.12[sources.16.12$V4=="GB",])
deletees<-which(duplicated(gb.all_dupesremaining$V6)==TRUE) #etsi duuppien positiot
gb.all<-gb.all_dupesremaining[-deletees,] #tee uusi datafreimi ilman duuppeja
lucky12<-gb.all[grep("(?i)http:\\/\\/www\\.(dailymail\\.co\\.uk|scotsman\\.com|telegraph\\.co\\.uk|thenorthernecho\\.co\\.uk|independent\\.co\\.uk|theguardian\\.com|liverpoolecho\\.co\\.uk|belfasttelegraph\\.co\\.uk|mirror\\.co\\.uk|eadt\\.co\\.uk|altonherald\\.com|lisburntoday\\.co\\.uk)",gb.all$V6,perl=T),] #tämä ilmeisesti olisi onnistuneesti poiminut kaikki tarvittavat lehdet ja myöskin case-insensitiivisesti.
names(lucky12)<-c("text_id","words","date","country","website","url","title")
write.table(lucky12,file="newlucky12.txt",quote=F,col.names=T,row.names = F,sep="\t")
getwd()
View(gb.all)
View(lucky12)
save.image("C:/Users/juho/Desktop/NOW_sorting_uptoDec31_16.RData")
load("C:/Users/juho/Desktop/NOW_sorting_uptoDec31_16.RData")
load("C:/Users/juho/Desktop/NOW_sorting_uptoDec31_16.RData")
View(sources.16.11)
load("C:/Users/juho/Desktop/NOW_sorting_uptoDec31_16.RData")
View(now_sources_pt1)
View(now_sources_pt2)
load("C:/Users/juho/Desktop/NOW_sorting_uptoDec31_16.RData")
date4eachword<-as.Date(rep(lucky12$date,lucky12$words))
load("C:/Users/juho/Desktop/NOW_sorting_uptoDec31_16.RData")
date4eachword<-rep(lucky12$date,lucky12$words)
head(date4eachword,10)
as.Date(head(date4eachword))
as.Date(head(date4eachword),format="%y %m %d")
as.Date(head(date4eachword),format="%y-%m-%d")
realdate4eachword<-as.Date(date4eachword,format="%y-%m-%d")
write.table(lucky12,file="newlucky12.txt",quote=F,col.names=T,row.names = F,sep="\t")
library("gsubfn", lib.loc="C:/Program Files/R/R-3.2.4revised/library")
nowGB14to16_files<-dir(path="c:/users/juho/desktop/NOW_GB_14-16",recursive=F,full.names=T) #täsmennetään tekstitiedostot sisältävä hakemisto
nowGB14to16_files<-dir(path="c:/users/juho/desktop/NOW_GB_14-16",recursive=F,full.names=T) #täsmennetään tekstitiedostot sisältävä hakemisto
for (i in nowGB14to16_files) {
tmp<-scan(file=i,what="char",sep="\n",quiet=T,encoding="UTF-8") #Nyt taas vaihteeksi täsmennämme UTF-8:n vaikka oikeasti se onkin UTF-8-BOM
cat(tmp,file="tempcorpusfile.txt",sep="\n",append=T) #tässä oli alunperin catin ekana argumenttina basename(i) mutta päätin sitten ettei filenameja täggerin ihmeteltäväksi.
cat("The contents of",i,"have been outputted into tempcorpusfile.txt.\n")
}
tehcorpus<-scan(file="tempcorpusfile.txt",what="char",sep="\n",encoding="UTF-8") #UTF-8-BOM
Mikko<-c("Penis,",
"Kives",
"Siitin",
"Peraereijus",
"Siittimenreijus",
8,
14,
"siinolisulleparinumeroo"
)
summary(Mikko)
Mikko
rm(Mikko)
(
Mikko<-c("Penis,",
"Kives",
"Siitin",
"Peraereijus",
"Siittimenreijus",
8,
14,
"siinolisulleparinumeroo"
)
)
rm(Mikko)
garbage.strings<-c( #Below are listed all the garbage strings to be removed.
"Trinity Mirror Merseyside , ([^\\s\\r\\n]+ ){167}campaigns \\.",
"(<[hp]> )?Advertising Department <[hp]>","(<[hp]> )?Send a story (<[hp]>)?",
"(<[hp]> )?Get daily news by email <[hp]>","<[hp]> Read More <[hp]>",
"<p> Video Loading <p> Video Unavailable <p> Click to playTap to play <p> The video will start in 8Cancel <p> Play now <p> Video will play in (<[hp]> )?",
"(<[hp]> )?Share this video <[hp]> Watch Next (<[hp]> )?","@ ([^\\s\\r\\n]+ ){165}awards and spearheaded numerous successful campaigns \\.",
"Trinity Mirror Merseyside , ([^\\s\\r\\n]+ ){150,200}@ @",
" Invalid e-mailThanks for subscribing ! Could not subscribe , try again later (<p> )?"
)
garbage.strings<-c( #Below are listed all the garbage strings to be removed.
"Trinity Mirror Merseyside , ([^\\s\\r\\n]+ ){167}campaigns \\.",
"(<[hp]> )?Advertising Department <[hp]>",
"(<[hp]> )?Send a story (<[hp]>)?",
"(<[hp]> )?Get daily news by email <[hp]>",
"<[hp]> Read More <[hp]>",
"<p> Video Loading <p> Video Unavailable <p> Click to playTap to play <p> The video will start in 8Cancel <p> Play now <p> Video will play in (<[hp]> )?",
"(<[hp]> )?Share this video <[hp]> Watch Next (<[hp]> )?",
"@ ([^\\s\\r\\n]+ ){165}awards and spearheaded numerous successful campaigns \\.",
"Trinity Mirror Merseyside , ([^\\s\\r\\n]+ ){150,200}@ @",
" Invalid e-mailThanks for subscribing ! Could not subscribe , try again later (<p> )?"
)
Sys.getlocale()
?pairs
install.packages("dplyr")
library("dplyr", lib.loc="~/R/win-library/3.3")
library(readr)
learning2014 <- read_csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt")
summary(learning2014)
summary(lm(Points ~ attitude + age + surf,
data=learning2014))
summary(lm(points ~ attitude + age + surf,
data=learning2014))
summary(lm(points ~ attitude, data=learning2014))
par(mfrow = c(2,2)); plot(lm(points ~ attitude, data=learning2014),which=c(2,4,6))
plot(lm(points ~ attitude, data=learning2014),which=1)
par(NULL)
plot(lm(points ~ attitude, data=learning2014),which=1)
par
?par
par(0)
plot(lm(points ~ attitude, data=learning2014),which=1)
variant<-sample(c("MS","SM","CovertM","Harmony"),100,c(.6.5.55.15))
variant<-sample(c("MS","SM","CovertM","Harmony"),100,c(.6,.5,.55,.15))
variant<-sample(c("MS","SM","CovertM","Harmony"),100,replace=T,c(.6,.5,.55,.15))
voice<-sample(c("active","passive",100,repace=T,c(.85,.15)))
is.negated<-sample(c(FALSE,TRUE),100,T,c(.85,.15))
trigger<-sample(c("demand.verb","suggest.verb","important.adj","order.noun"),1000,T,c(.6,.5,.3,.15))
variant<-sample(c("MS","SM","CovertM","Harmony"),1000,replace=T,c(.6,.5,.55,.15))
voice<-sample(c("active","passive",1000,repace=T,c(.85,.15)))
is.negated<-sample(c(FALSE,TRUE),1000,T,c(.85,.15))
voice<-sample(c("active","passive",1000,replace=T,c(.85,.15)))
voice<-sample(c("active","passive"),1000,replace=T,c(.85,.15)))
voice<-sample(c("active","passive"),1000,replace=T,c(.85,.15))
voice<-sample(c("active","passive"),1000,replace=T,c(.85,.15))
trigger<-sample(c("demand.verb","suggest","insist","recommend","important","essential","order","request","demand.noun"),1000,T,c(60,50,40,55,25,20,25,30,30))
Variant<-sample(c("MS","SM","CovertM","Harmony"),100,replace=T,c(.6,.5,.55,.15))
IsNegated<-sample(c(FALSE,TRUE),1000,T,c(.85,.15))
Voice<-sample(c("active","passive"),1000,replace=T,c(.85,.15))
Trigger<-sample(c("demand.verb","suggest","insist","recommend","important","essential","order","request","demand.noun"),1000,T,c(60,50,40,55,25,20,25,30,30))
rm(is.negated,trigger,variant,voice)
OvertThat<-sample(c(TRUE,FALSE),1000,T,c(70,30))
Trigger<-sample(c("demand.verb","suggest","insist","recommend","important","essential","order","request","demand.noun","ask"),1000,T,c(60,50,40,55,25,20,25,30,30,18))
SubjectReluctant<-sample(c(TRUE,FALSE),1000,T,c(50,50))
MockData<-data.frame(Variant,Trigger,Voice,OvertThat,IsNegated,SubjectReluctant)
View(MockData)
?cforest
install.packages("party")
library("party", lib.loc="~/R/win-library/3.3")
install.packages("designGLMM")
?cforest
metsae<-cforest(Variant~Trigger+Voice+OvertThat+SubjectReluctant+IsNegated, data=MockData)
metsae2<-varimp(metsae)
dotchart(sort(metsae2))
?ctree
puu<-ctree(Variant~Trigger+Voice+OvertThat+SubjectReluctant+IsNegated,data=MockData)
plot(puu)
library("ggplot2", lib.loc="~/R/win-library/3.3")
qplot(puu)
ctree(Variant ~ Trigger+Voice+OvertThat+SubjectReluctant+IsNegated, data = MockData)
plot(ctree(Variant ~ Trigger+Voice+OvertThat+SubjectReluctant+IsNegated, data = MockData))
rm(GCtorture)
table(variant)
table(Variant)
Variant<-sample(c("MS","SM","CovertM","Harmony"),1000,replace=T,c(.6,.5,.55,.15))
IsNegated<-sample(c(FALSE,TRUE),1000,T,c(.85,.15))
Voice<-sample(c("active","passive"),1000,replace=T,c(.85,.15))
Trigger<-sample(c("demand.verb","suggest","insist","recommend","important","essential","order","request","demand.noun","ask"),1000,T,c(60,50,40,55,25,20,25,30,30,18))
OvertThat<-sample(c(TRUE,FALSE),1000,T,c(70,30))
SubjectReluctant<-sample(c(TRUE,FALSE),1000,T,c(50,50))
View(MockData)
table(Variant)
puu<-ctree(Variant~Trigger+Voice+OvertThat+SubjectReluctant+IsNegated,data=MockData)
plot(puu)
View(MockData)
puu<-ctree(Variant ~ IsNegated+IsReluctant, data=MockData)
puu<-ctree(Variant ~ IsNegated+SubjectReluctant, data=MockData)
plot(puu)
puu
library(readr)
datafile <- read_delim("C:/Users/juho/Desktop/00_Tutkimusjutut/Round3/article/parempikorpus/datafile.txt",
"\t", escape_double = FALSE, trim_ws = TRUE)
View(datafile)
datafile.ctree<-ctree(depvar~X3w_str+strgt_n+amb+trg+pos,data=datatable)
datafile.ctree<-ctree(depvar~X3w_str+strgt_n+amb+trg+pos,data=datafile)
datafile.ctree<-ctree(depvar~t_strgt+ambig+pos+yr+trgr,data=datafile)
elarbol<-ctree(depvar ~ trgr+t_strgt+ambig+pos+yr,data=datafile)
str(datafile)
datatable$depvar<-as.factor(datatable$depvar)
datafile$depvar<-as.factor(datafile$depvar)
datafile$trgr<-as.factor(datafile$trgr)
datafile$ambig<-as.factor(datafile$ambig)
datafile$yr<-as.factor(datafile$yr)
str(datafile)
conditiontree<-ctree(depvar ~ trgr+trg_strgt+ambig+pos+yr)
conditiontree<-ctree(depvar ~ trgr+trg_strgt+ambig+pos+yr, data = datafile)
conditiontree<-ctree(depvar ~ trgr+t_strgt+ambig+pos+yr, data = datafile)
str(datafile)
datafile$pos<-as.factor(datafile$pos)
conditiontree<-ctree(depvar ~ trgr+t_strgt+ambig+pos+yr, data = datafile)
plot(conditiontree)
conditiontree
rep("mikko","matti","pekka",each=3)
rep(c("mikko","matti","pekka"), each=3)
rep(c("mikko","matti","pekka"), 3)
library("ggplot2", lib.loc="~/R/win-library/3.3")
library("GGally", lib.loc="~/R/win-library/3.3")
library(MASS)
data("Boston")
str(Boston);View(Boston)
summary(Boston)
library("corrplot", lib.loc="~/R/win-library/3.3");library("tidyverse", lib.loc="~/R/win-library/3.3")
(matriisi<-cor(Boston)) %>% corrplot(method="circle")
Boston.unscaled<-Boston #Backing up the unscaled version
Boston<-scale(Boston)
summary(Boston)
Boston<-as.data.frame(Boston)
(kvantiilit<-quantile(Boston$crim))
Boston$crime.factor<-cut(Boston$crim, kvantiilit, include.lowest = TRUE, labels=c("low","low-ish","high-ish","high"))
Boston<-Boston[,-1]
set.seed(10)
TrainingRows<-sample(nrow(Boston),size=nrow(Boston)*.8) #Randomly select 80% of all rows
TrainingSet<-Boston[TrainingRows,] #Create training set
TestingSet<-Boston[-TrainingRows,] #Create testing set
head(TrainingSet)
head(TestingSet)
(lda.fit<-lda(crime.factor ~ ., data = TrainingSet))
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(TrainingSet$crime.factor)
plot(lda.fit, dimen = 2, col=classes, pch=classes);lda.arrows(lda.fit, myscale = 1.5)
correct.classes<-TestingSet$crime.factor
TestingSet<-TestingSet[,which(colnames(TestingSet)!="crime.factor")]
lda.pred <- predict(lda.fit, newdata = TestingSet)
table(real = correct.classes, predicted = lda.pred$class)
Boston.adulterated<-Boston #Back up the version in which crime is a factor.
Boston<-as.data.frame(scale(Boston.unscaled)) #Scale the original version of Boston and make sure the result is a data frame:
head(Boston)
dist_eu<-dist(Boston)
k_max <- 10;twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss});plot(1:k_max, twcss, type='b')
library("ggplot2", lib.loc="~/R/win-library/3.3")
library("GGally", lib.loc="~/R/win-library/3.3")
library("ggplot2", lib.loc="~/R/win-library/3.3")
library("GGally", lib.loc="~/R/win-library/3.3")
library("ggplot2", lib.loc="~/R/win-library/3.3")
library("GGally", lib.loc="~/R/win-library/3.3")
library(MASS)
data("Boston")
str(Boston);View(Boston)
summary(Boston)
library("corrplot");library("tidyverse")
(matriisi<-cor(Boston)) %>% corrplot(method="circle")
Boston.unscaled<-Boston #Backing up the unscaled version
Boston<-scale(Boston)
summary(Boston)
Boston<-as.data.frame(Boston)
(kvantiilit<-quantile(Boston$crim))
Boston$crime.factor<-cut(Boston$crim, kvantiilit, include.lowest = TRUE, labels=c("low","low-ish","high-ish","high"))
Boston<-Boston[,-1]
set.seed(10)
TrainingRows<-sample(nrow(Boston),size=nrow(Boston)*.8) #Randomly select 80% of all rows
TrainingSet<-Boston[TrainingRows,] #Create training set
TestingSet<-Boston[-TrainingRows,] #Create testing set
head(TrainingSet)
head(TestingSet)
(lda.fit<-lda(crime.factor ~ ., data = TrainingSet))
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
heads <- coef(x)
arrows(x0 = 0, y0 = 0,
x1 = myscale * heads[,choices[1]],
y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
text(myscale * heads[,choices], labels = row.names(heads),
cex = tex, col=color, pos=3)
}
classes <- as.numeric(TrainingSet$crime.factor)
plot(lda.fit, dimen = 2, col=classes, pch=classes);lda.arrows(lda.fit, myscale = 1.5)
correct.classes<-TestingSet$crime.factor
TestingSet<-TestingSet[,which(colnames(TestingSet)!="crime.factor")]
lda.pred <- predict(lda.fit, newdata = TestingSet)
table(real = correct.classes, predicted = lda.pred$class)
Boston.adulterated<-Boston #Back up the version in which crime is a factor.
Boston<-as.data.frame(scale(Boston.unscaled)) #Scale the original version of Boston and make sure the result is a data frame:
head(Boston)
dist_eu<-dist(Boston)
k_max <- 10;twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss});plot(1:k_max, twcss, type='b')
pairs(Boston, col = km$cluster)
km <-kmeans(dist_eu, centers = 2)
pairs(Boston, col = km$cluster)
km4<-kmeans(dist_eu, centers = 4)
str(km4)
summary(km4$cluster)
str(Boston)
Boston$cluster<-km4$cluster
(ld4.4c<-lda(cluster ~ ., data=Boston))
View(Boston)
summary(Boston.unscaled$nox)
str(Boston.unscaled$nox)
View(Boston.unscaled)
View(Boston)
luokat <- Boston$cluster
plot(lda.4c, dimen = 2, col=luokat, pch=luokat);lda.arrows(lda.4c, myscale = 1.5)
plot(ld4.4c, dimen = 2, col=luokat, pch=luokat);lda.arrows(ld4.4c, myscale = 1.5)
data()
data("iris")
data("iris")
setwd(dir="c:/users/juho/desktop/IODS-project/IODS-project")
human <- read.table("C:/Users/juho/Desktop/IODS-project/IODS-project/data/human.txt", header=T, sep="\t",quote=NULL)
library(ggplot2)
library(GGally)
ggpairs(human, mapping = aes(alpha=0.3), lower = list(combo = wrap("facethist", bins = 20))) + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
(pca<-prcomp(human))
(pca.summary<-summary(pca))
prossat<-round(100*pca.summary$importance[2, ], digits = 1)
laabelitjaleibelit<-paste0(names(prossat), " (", prossat, "%)")
biplot(pca, cex = c(0.8, 1), col = c("blue", "red"), xlab = laabelitjaleibelit[1], ylab = laabelitjaleibelit[2], main="Human development (unscaled) by two principal components")
human.scaled<-scale(human)
pca.scaled<-prcomp(human.scaled)
(pca.scaled.summary<-summary(pca.scaled))
rosentit<-round(100*pca.scaled.summary$importance[2, ], digits = 1)
akselit<-paste0(names(rosentit), " (", rosentit, "%)")
biplot(pca.scaled, cex = c(0.8, 1), col = c("darkgreen", "purple"), xlab = akselit[1], ylab = akselit[2], main="Human development (scaled) by two principal components")
library(FactoMineR)
data(tea)
str(tea)
summary(tea)
tea.backup<-tea
tea<-tea[,c("Tea","How","how","where","sugar","lunch")]
head(tea)
library(tidyr)
gather(tea) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))
tea.mca<-MCA(tea)
(mca.summary<-summary(tea.mca))
tea.mca
khaki<-summary(tea.mca)
?summary
(base::mca.summary<-summary(tea.mca))
base::summary
(mca.summary<-base::summary(tea.mca))
summary
